以下は、提供された5chログ（437から637までのレス）から、指定された生成AIの「モデル」に関する話題をすべて抽出したものです。抽出の基準は以下の通りです：

- 指定されたモデル（NovelAI v4/v3 (NAI), Pony, illustrious 0.1/1.0/1.1/2/3/3.5vpred (イラストリアス, リアス, ill), Noobai, FLUX/HiDream, Wan 2.1/2.2 (wan), FramePack, Qwen）に関連する言及をすべて抽出。
- モデル名が直接的に登場したり、議論されたりする箇所に限定。
- 特に、そのモデルが選ばれている理由（例: 性能、簡単さ、綺麗さなど）が明示されている場合、それを強調して抽出。
- 抽出はログのレス番号を基に整理し、重複を避けつつ文脈を簡潔にまとめ。関連のない話題（例: ComfyUIのUI操作、ツールのインストールなど）は除外。
- 該当なしのモデル（FLUX, HiDream）は記載なし。

### NovelAI v4/v3 (NAI)
- 563: NAIちゃんのキャラ参照機能を使わせてくれ。結構精度良さそうじゃない。
- 618: NAIしか知らなかった時は二の足踏んでたけど、ローカルでそこそこでも動く環境があるなら、追加課金なしでローカルでも出来ると知ってAIイラスト始めたな。エロを期待できるのはNAIちゃんくらいやけど万能っていうわけでもない。
- 623: NAIにローカルのCNとかの拡張機能が使えれば無敵なんやがな。現在テスト中のキャラ固定化機能は面白そうやな。誰かがそれをパクった拡張機能作りそうやが。
  - **選ばれている理由**: キャラ固定化機能が面白そうで期待。エロ生成の期待値が高いが、万能ではない。ローカルのCN拡張機能との組み合わせで無敵になる可能性。
- 630: ローカルの強化版リファレンスオンリーみたいな新機能楽しみやよね。ワイもひっさしぶりに月額課金するかなって期待しとる。
  - **選ばれている理由**: 新機能（キャラ固定化）が楽しみで、月額課金する価値あり。

### Pony
- 510: pony慣れてるし、qwenもでたし、いいかなあ。と思ってたのですが、イラストリアス試しにどうなんだろう？と思って使ってみたのですが。。。ええ。ポンだしでここまで綺麗にでるもんなんですか！？すごすぎ。こりゃゴールいうわけだ。
  - **選ばれている理由**: 慣れているため（ただし、イラストリアスに切り替えて綺麗さに驚き、ゴールと評価）。

### illustrious 0.1/1.0/1.1/2/3/3.5vpred (イラストリアス, リアス, ill)
- 510: pony慣れてるし、qwenもでたし、いいかなあ。と思ってたのですが、イラストリアス試しにどうなんだろう？と思って使ってみたのですが。。。ええ。ポンだしでここまで綺麗にでるもんなんですか！？すごすぎ。こりゃゴールいうわけだ。
  - **選ばれている理由**: ポンだし（プロンプトのみ）で綺麗に出るため。すごすぎてゴールと評価。
- 585: あれだけ持て囃されたイラストリアスもSDXLかや脱却は出来てないからなぁ。
- 587: いま周回遅れでリアスに目覚めてるんですけど。やはりsdxlなの？　なんか普通にanytest使えたから頭？？？になってる。
- 615: イラストリアス、sdxl？　なんか普通にanytest使えたから頭？？？になってる。
- 617: イラストリアスといえども所詮ベースはSDXLということやで。なんだかんだもうリリースから2年経っとるからな。
- 624: リアスもその派生のNoobAIもSDXLやで。月須和ニキのAnyなんちゃら系は使えるっちゃ使えるけど、各ベースモデルで制作したものが公開されているからそれを使ったほうが確実やと思う。
  - **選ばれている理由**: SDXLベースだが、各ベースモデルで制作されたものが公開されており、確実性が高い。Anytest系は使えるが、専用ベースモデルの方がおすすめ。

### Noobai
- 624: リアスもその派生のNoobAIもSDXLやで。

### Wan 2.1/2.2 (wan)
- 452: >>422ニキのrgthree切り替え方式はWan2.2のノードに組み込んで>>440ニキの自作切り替えノードは静止画のノードに組み込んだやで。これで解像度手入力生活からバイバイや！サンガツ！
- 456: EasyWan22でEndImageありでRefinerするとエラーになる不具合を修正してコミットしといたで。>>448 BlocksToSwapはLoRAを手動設定するModelLoaderの下の方にあるで。
- 457: 病院から一週間ぶりに戻ってきたで。FramePack_P1はまだ出てないんか。Wan22に手をつけるかなあ。
- 484: 動画作って見たくてwan22で動画作って見たけれどcomfyUI使った事無かったからこっちに苦戦だわ。
- 488: Wan2.1のころの話やがfp16モデルとかLoRA使うと普通に150GBぐらい使うで。そこから何度かモデル切り替えたりしてると192GB限界まで使い切る。プチ浦島のWan2.2童貞なんで最近のは分からん。メモリはあればあるだけ有効活用しようとするから腐ることはない。
  - **選ばれている理由**: fp16モデルやLoRA使用でメモリを大量消費するが、有効活用可能で腐らない。
- 489: バグかしらんがWAN系は一度出力するとそれまで使ったメモリがパージされないからPython.exeを手動で終了させない限りどんどんメモリを食い潰していく。
- 490: ここ2週間くらいのワイがそうや楽しすぎて、RouWei-Gemma、QwenImage（Edit両立）、Wan22（kijai版自己流）、Wan22（ネイティブ3ステージ）のワークフロー作ってもうた。色々試行錯誤するのがオモロいんよね。
  - **選ばれている理由**: 試行錯誤が面白い。kijai版自己流やネイティブ3ステージなどのバリエーションでワークフロー作成。
- 492: それたぶんWanじゃなくてPytorch2.8.0の新仕様やぞ。一生メモリパージしないから128GBだろうと256GBだろうとスワップしまくる。
- 511: reforge 1.7.0のtorchを2.7.1に上げて、sageAttention2++入れて起動して生成もできた。曰く付きのnumpy2ぶっこまれそうになったけどなんとか耐えたわ。動画ばかりやったからreForgeで久々の画像、もう旧forge使わなくてもええかな。>>508 温度ありがとうございました。こんなもんなんですね。安心しました。自分も数日前にポータブルのほうに++導入しようとして難儀してました。multitalkとかのwfでwanvideowrapperでのモデルローダーでsageの切り替えできるから、二回目以降なら効果の計測ができそう？！
- 512: wan2.2で腰を大きく前後に動かすのってどういうプロンプト？セックスさせたいんじゃなくて腰を動かしたいんだ。
- 517: 以前こちらで紹介されてた一つにハイロー統合したwanのnfswモデルでてました。Phr00t/WAN2.2-14B-Rapid-AllInOne。
- 537: wan-2.2 s2vのcomfy対応まだかなーとかページみてたらDiffSynth-Studioとかいうのあったんだけど、A1111のようなWEBUIとからしいんだけど、comfy 苦手な人には朗報？！
- 556: イッテンゴanimatediffから一気にwan22に来たけどanimatediffの知識が全部ドブ行きにならなくてComfyUIネイティブ対応はマジで助かる。
  - **選ばれている理由**: animatediffからの移行で知識が活き、ComfyUIネイティブ対応が助かる。
- 590: 正直日本の大半のAIユーザーはリアスとFramePackで静止画も動画もゴールだと思ってるわ。今更FramePack？と思う奴もおるかもしれんが単純に女の子キャラにぶっかけやフェラ、脱ぎパイやキス、ピストンさせたいだけならWan2.1や2.2使うよりFramePackの方が確実に簡単やろ。
  - **選ばれている理由**: 比較として、Wan2.1/2.2よりFramePackの方が簡単（ただし、全体としてリアスとFramePackでゴールと評価）。
- 595: 出来る事が増えてもやる事はずっと変わらんのよな。ほんなら軽くて速いFramePackでええやん理論やで。
  - **選ばれている理由**: 比較として、軽くて速いFramePackの方が良い（Wan2.2との比較）。
- 605: wan2.1でも2.2でもええからバイパンにする方法教えてくれへんか。プロンプトでやってもネガティブプロンプトでやってもloraでやっても生えてくんねん。
- 606: そもそも動画にして動かせるんやからWAN22も理論上nanobananaみたいなこと出来ると思うが。
- 620: wan2.1でも2.2でもええからバイパンにする方法教えてくれへんか。

### FramePack
- 457: FramePack_P1はまだ出てないんか。Wan22に手をつけるかなあ。
- 590: 正直日本の大半のAIユーザーはリアスとFramePackで静止画も動画もゴールだと思ってるわ。今更FramePack？と思う奴もおるかもしれんが単純に女の子キャラにぶっかけやフェラ、脱ぎパイやキス、ピストンさせたいだけならWan2.1や2.2使うよりFramePackの方が確実に簡単やろ。
  - **選ばれている理由**: 静止画/動画のゴール。Wan2.1/2.2より確実に簡単で、ぶっかけ/フェラ/ピストンなどのシンプルな用途に適する。
- 595: 出来る事が増えてもやる事はずっと変わらんのよな。ほんなら軽くて速いFramePackでええやん理論やで。
  - **選ばれている理由**: 軽くて速いため。Wan2.2との比較でシンプルな用途に適する。

### Qwen
- 490: RouWei-Gemma、QwenImage（Edit両立）、Wan22（kijai版自己流）、Wan22（ネイティブ3ステージ）のワークフロー作ってもうた。色々試行錯誤するのがオモロいんよね。
  - **選ばれている理由**: Edit両立が可能で、試行錯誤が面白い。
- 510: pony慣れてるし、qwenもでたし、いいかなあ。
- 511: multitalkとかのwfでwanvideowrapperでのモデルローダーでsageの切り替えできるから、二回目以降なら効果の計測ができそう？！あと比較的重いからqwen-imageでもkjnodeのsageノードでオンオフで計測？？
- 514: multitalkとかのwfでwanvideowrapperでのモデルローダーでsageの切り替えできるから、二回目以降なら効果の計測ができそう？！あと比較的重いからqwen-imageでもkjnodeのsageノードでオンオフで計測？？

抽出の結果、Wan 2.1/2.2が最も多く言及されており、動画生成やワークフロー関連の議論が中心。IllustriousはSDXLベースの綺麗さとゴール評価で注目。理由として、簡単さ、綺麗さ、メモリ効率、試行錯誤の楽しさが挙げられるものが多かった。もし追加の文脈や不明点があれば、教えてください。

---以下は、提供された5chログ（437〜637）から、生成AIの「モデル」に関する話題を抽出したものです。抽出の基準は以下の通りです：

- **対象**: 生成AI（主に画像生成AI）のモデルに関する言及。音声生成モデル（例: Style-Bert-VITS2）も生成AIの範疇として含めました。
- **除外**: 指定された除外モデル一覧（NovelAI v4/v3 (NAI), Pony, illustrious 0.1/1.0/1.1/2/3/3.5vpred (イラストリアス, リアス, ill), Noobai, FLUX, HiDream, Wan 2.1/2.2 (wan), FramePack, Qwen）に該当するものは除外。これらに関連する派生モデル（例: QwenImage, Phr00t/WAN2.2-14B-Rapid-AllInOne）も除外対象とみなしました。
- **抽出の焦点**: 除外対象外のモデル名が出てくる箇所を抽出。特に、そのモデルが選ばれている理由（例: 性能、使いやすさ、特定の機能）が述べられている場合、それを強調して抽出。
- **全体の傾向**: ログの多くは除外対象のモデル（Wan, Illustrious, Qwen, FramePackなど）に関する議論が中心ですが、それらを除くと、SDXLベースのモデルやGoogleのGemini関連、音声モデルなどが散見されます。抽出数は限定的です。

### 抽出結果
#### 1. Style-Bert-VITS2 (音声生成モデル)
- **関連レス**: 457, 461
- **内容抽出**:
  - 457: 「リタニキがStyle-Bert-VITS2のメジャーバージョンアップしてるじゃないか、こりゃめでたい。」
  - 461: 「Style-Bert-VITS2どんな更新入ったか見てくるかのう　情報サンガツ」
- **選ばれている理由**: メジャーアップデートがあり、めでたい（喜ばしい）という評価。病院からの退院後のリハビリとしてLoRAを落として使っている文脈から、使いやすさや更新の新鮮さが理由として挙げられる。音声生成の文脈で、画像生成との組み合わせ（例: リハビリでLoRA作成）が示唆されている。

#### 2. SDXL (Stable Diffusion XL, 画像生成モデル)
- **関連レス**: 455, 466, 510, 615, 617, 624, 625
- **内容抽出**:
  - 455: 「女の子もちんちんもSDXL製やからね　外人サイズやねんｗ」
  - 466: 「SDXLサイズでよく使う896*1152や832*1216がプリセットにないのは意外やけど」
  - 510: 「イラストリアス試しにどうなんだろう？と思って使ってみたのですが。。。 ええ。ポンだしでここまで綺麗にでるもんなんですか！？ すごすぎ。こりゃゴールいうわけだ。」（※イラストリアスは除外だが、SDXLとの比較で言及）
  - 615: 「やはりsdxlなの？　なんか普通にanytest使えたから 頭？？？になってる。」
  - 617: 「イラストリアスといえども所詮ベースはSDXLということやで  なんだかんだもうリリースから2年経っとるからな」
  - 624: 「月須和ニキのAnyなんちゃら系は使えるっちゃ使えるけど、各ベースモデルで制作したものが公開されているからそれを使ったほうが確実やと思う」（※AnyTest/Anyなんちゃら系はSDXLベースの派生モデルとして言及）
  - 625: 「SDXLといえばCLIPの代わりにGemmaを使って性能を拡張するってのは実際どうなんやろうな  noteの記事読む限りはポーズなどの表現はよくなる的な事が描かれているけど、NSFWというかexplicitみたいな画像のクオリティも上がるかや  しかしこういう性能的に最先端ではなくなったモデルを強化する案があるってのはロボットアニメ的で好きやで  G3ガンダムというかガンダムEz8というか」
- **選ばれている理由**:
  - SDXLはベースモデルとして広く使われており、2年経過しても安定性が高い（617）。ポン出し（プロンプトのみ）で綺麗に出力できる点が評価されている（510, ただしイラストリアスとの比較）。
  - AnyTest/Anyなんちゃら系はSDXLベースで使えるが、各ベースモデルで公開されたものを選ぶと確実性が高い（624）。これは使いやすさと信頼性を理由とする。
  - GemmaをCLIPの代替として使うことで、ポーズ表現が向上し、NSFW画像のクオリティも期待される（625）。性能的に古くなったSDXLを強化する点が「ロボットアニメ的で好き」と好評価。explicit（露骨な）画像生成のクオリティ向上を狙う理由が明確。

#### 3. nano banana / Gemini 2.5 Flash Image (Googleの画像生成モデル, 別名: Gemini-flash-2.5-image-preview)
- **関連レス**: 534, 535, 543, 555, 557, 558, 559, 570, 582, 599, 600, 602, 607, 627
- **内容抽出**:
  - 534: 「nano banana（Gemini 2.5 Flash Image）来てたで  今のところ使いたい放題なんやが制限あるんやろか」 （画像例あり）
  - 535: 「この現実味あるアジアン体型すき  凄いね、reference_seetが苦労せず作れる」
  - 543: 「nano-banana、もといGemini-flash-2.5-image-previewやってみた  凄いっちゃ凄いけど、元絵への依存レベルが半端ないから  用途がかなり限られるね、画風を変えるとかは無理そう」
  - 555: 「すごE  でもエロなしならチャッピーの方がええのか？」（チャッピー=ChatGPTとの比較）
  - 557: 「チャッピーは「チャッピーで作りました！」感が強烈だから、いっそチャッピーで作った画像をnano banana通すのもありかも  でも思ったより再現度が高くないというか、投入した画像と微妙に髪型や髪色が違うことがあるな  インナーカラーのキャラを投入したらなぜか毛先の色が変わったりとか」
  - 558: 「元ネタありならbanana、元ネタなしならgptって感じ  用途的にはクリエイターに需要ありそう」
  - 559: 「あと細かく指定しないと読み込ませたもんまんま出してくる」
  - 570: 「nano-banana、リリース前にLMArenaで使えてた時の方が解像度良かったの草」
  - 582: 「んほーbananaしゅごい・・」（画像例あり）
  - 599/600: 「バナナはどうやったら使えるんや？ ... Failed to generate content: permission denied.」（使い方の質問）
  - 602: 「バナナはAPIキーがウンタラでよくわからん諦めた」
  - 607: 「そもそもAPIの無料枠で使えるんかねBananaは」
  - 627: 「拘り勢からするとなんかちゃうってなりそうな感じやなー  相当いろいろな画風学習させてるんやろなってのはわかる」
- **選ばれている理由**:
  - 現実味のある体型（アジアン体型）やreference sheet（参照シート）の簡単生成が可能で、苦労せずに作れる（534, 535）。使いたい放題（制限なし？）の点が魅力（534）。
  - 元絵への依存が強く、画風変更は無理だが、再現度が高い（543）。チャッピー（ChatGPT）と比較して、元ネタありの用途で優位（555, 557, 558）。クリエイター向けの需要が高い（558）。細かい指定で調整可能（559）。
  - リリース前の解像度が高かったが、現在は制限やエラーが発生しやすい（570, 599, 600, 602, 607）。多様な画風学習による自然さ（627）が評価される一方、拘り勢には「なんかちゃう」と感じる場合あり。
  - 全体として、無料API枠の利便性と、画像投入による高再現度が選ばれる主な理由。エロなしの一般イラスト生成で強い（555）。

#### 4. DiffSynth-Studio (拡散モデル関連ツール/モデル)
- **関連レス**: 537, 541, 545, 550, 551, 552
- **内容抽出**:
  - 537: 「DiffSynth-Studio とかいうのあったんだけど、    A1111のようなWEBUIとからしいんだけど、  comfy 苦手な人には朗報？！」
  - 541: 「DiffSynth StudioググってもUIの画像1枚もないの草  謎のツールすぎんか」
  - 545: 「なんか中国のサイトのサービスみたいね。ssd来たら試しにいれてみます。」
  - 550: 「githubにあるDiffSynth-Studioは生成も出来るmusubi-tunerみたいな感じっぽいがこれとは別なんか？」
  - 551: 「同じだとおもいます。  トレーニングとかあるから、そっち方面なのかな？  でも包括的なとか書いてるけど。」
  - 552: 「GitHub - modelscope/DiffSynth-Studio: 拡散モデルの魔法をお楽しみください!」
- **選ばれている理由**: ComfyUIが苦手な人向けのA1111風WEBUIとして朗報（537）。トレーニング機能があり、包括的な拡散モデル生成が可能（551）。中国サイト経由のサービスで、生成とチューニングの両立が魅力だが、謎が多く情報が少ない（541, 545）。GitHubで公開されており、拡散モデルの「魔法を楽しむ」用途で選ばれる（552）。

### 追加の考察
- **抽出件数の少なさ**: ログの大部分が除外対象モデル（Wan, Illustrious, Qwenなど）に集中しており、除外外のモデル話題は限定的。SDXLはベースモデルとして頻出だが、派生の文脈が多い。
- **理由の傾向**: 選ばれる理由は主に「使いやすさ（確実性、無料放題）」「性能向上（再現度、表現力）」「更新の新鮮さ」が目立つ。NSFW用途の言及もあるが、ログ全体でエロ関連は除外モデルに偏っている。
- **不明点**: もし抽出基準の解釈（例: QwenImageの除外判断、音声モデルの含否）で不明瞭な点があれば、追加で教えてください。