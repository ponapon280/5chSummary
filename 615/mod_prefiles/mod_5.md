### 抽出結果: 指定モデルに関する話題

ログ全体（841-1000）をスキャンし、指定モデル（NovelAI (NAI), Pony, illustrious(イラストリアス, リアス,ill,IL), Noobai, FLUX, Wan, Qwen）に関する言及をすべて抽出。Pony, illustrious(イラストリアス, リアス,ill,IL), Noobai, FLUX の言及は**なし**。

#### NovelAI (NAI)
- **989**: 「模様替えしてたらPCぶっ壊してしまった(物理)のでnaiを久々に使うわ  4.5って結構前からだっけ？特に変わってないよな」
  - 理由: PC物理破損でローカル環境が使えなくなり、代替としてNovelAI (nai) に戻る。バージョン4.5の更新状況を確認（特に変わっていない印象）。

- **981**: 「有料オンラインサービスで一番コスパいいのってどれなん？  novelaiとかpixaiはアニメ特化だしgrokは規制されたし、nudefusionとかになるんか？」
  - 理由: 有料オンラインサービスのコスパ比較で言及。アニメ特化が特徴として挙げられる。

#### Wan
- **842**: 「WAN2.2をGGUFにして4step LORAにしたら1分で5秒の動画出てくるようになったが、これsageとtritonいれてdistillモデルにしたらもっと速くなる？4090なんやが」
  - 理由: GGUF量化 + 4step LoRA適用で高速化（1分で5秒動画）。さらにsage/triton/distillで速度向上を期待（4090環境）。

- **862**: 「昨日の夜辺りにgrokのモデルがまた新しくなってwanにNSFW系LoRA使った時みたいに常に揺れてて高速動作するようになってしまった」
  - 理由: wan + NSFW LoRA使用時の挙動（揺れ + 高速動作）とgrokモデルの類似を比較。

- **868**: 「Wan2.2のI2VでHighの処理とLowの処理を別々に動かすFW作ってみた。①Highの処理とLowの処理を単独実行・連続実行どちらも可能 ②SamplerCustomAdvancedってのが、ノイズ有り／無しの2つの出力を持っているので High処理でのガチャ確認に利用。③LatentSender/LatentReceiverノードで Highの処理からLowの処理に一時保存Latentを受け渡す仕組み。」
  - 理由: Wan2.2のI2V（Image-to-Video）でHigh/Low処理を分離するカスタムワークフロー作成。ノイズ有無出力でガチャ確認、Latent受け渡しで効率化。

- **943**: 「やっぱここで継ぎ足したなというのが気になってしまう  個人的にはいろいろ継ぎ目がわからないという利点が大きいSVIのほうがすき、ダイナミックな動きはできないもしくは維持力放棄で実質破綻だろうけどね」（Wan2.2触ってない人は気にならないが、触っていると継ぎ目がわかる）
  - 理由: Wan2.2使用時の継ぎ目（動画延長時の違和感）が目立つ欠点として指摘。一貫性重視でSVI推奨。

- **946**: 「WAN2.2で排泄させられる LORAある？」
  - 理由: WAN2.2 + 特定LoRA（排泄描写）で特殊生成を試す相談。

- **977**: 「High:Dasiwan,low:Dasiwanですが色々モデル試している感じモデルにもよりそうですね。」
  - 理由: SVI時の顔一貫性問題でDasiwan（Wan派生？）をHigh/Lowで使用。モデル依存の挙動を確認中。

#### Qwen
- **879**: 「qwen2512でggufは普通に出力出来るんやがfp8がcomfy公式のフロー使ってもまともに出ないんやが  呪いかナニかやろか」
  - 理由: qwen2512のGGUF出力は正常だが、FP8量化がComfyUI公式フローで失敗。トラブル相談。

- **881**: 「sage attentionとかその辺が原因ちゃうかったか」（>>879への返信）
  - 理由: qwen2512 FP8失敗の原因としてsage attentionを指摘。

- **882**: 「QwenImageEdit+LoRAでガチャ回せば出る気がする」
  - 理由: ウルトラの母画像編集でQwenImageEdit + LoRAを提案（ガチャで生成可能）。

- **884**: 「Qwen以外のモデルだとFP8は行けたりするのでなんか紛らわしいけど  実用的にはGGUFのQ8にするかBF16もってくるかで解決する」「グラボの3000番代がFP8は無理ということじゃなかったかな、あとはCudaやPytorchのVer周り」
  - 理由: QwenのFP8非対応（グラボ3000番代/Cuda/Pytorch依存）。代替としてGGUF Q8/BF16推奨で実用解決。

- **885**: 「fp8のがちょっと速いけどそれやったらナシやなサンガツ」（>>881への同意）
  - 理由: FP8の速度優位性を認めつつ、qwen2512では使えず。

- **887**: 「edit2511のnvfp4が動いたんで2512はggufで我慢してかなり速くなったeditでヒャッハーするで」「5000番代で2.9+cu130なんで環境的には問題ないハズなんやがね」
  - 理由: Qwen edit2511のnvfp4成功、edit2512はGGUFで高速化（5000番代グラボ環境）。FP8失敗をGGUFで回避し満足。

- **893**: 「QWENなんかを使ったか」
  - 理由: ウルトラの母画像生成/編集ツールとしてQWENを候補挙上（チンマン出さなければオンライン可）。

- **908**: 「巨乳用loraとか持ってないからこれくらいが限界だったわ  →qie」
  - 理由: qie（Qwen Image Edit?）使用時の生成結果共有。巨乳LoRAなしで限界描写。

**抽出まとめ**:
- **Wan**が最多（主にWAN2.2動画生成の高速化/ワークフロー/LoRA適用/継ぎ目問題）。
- **Qwen**は量化（GGUF/FP8）トラブルとImageEditの編集用途中心。速度/実用性でGGUF推奨。
- **NovelAI**は代替/オンラインサービスとしての言及。
- 理由は主に**速度向上、量化対応、動画/画像生成の効率化/編集、環境依存のトラブル回避**。

---

### 抽出された生成AIモデル関連話題（除外モデル除く）

以下は、提供ログから**生成AIの「モデル」**（主に画像/動画/音楽生成関連の基盤モデル）を指す言及を抽出したものです。除外リスト（NovelAI/NAI, Pony, illustrious/イラストリアス/リアス/ill/IL, Noobai, FLUX, Wan, Qwen）に該当・関連するものは一切除外。モデル名が明確で話題の中心となっているもののみ対象とし、ツール/手法（例: SVI, FLF, ComfyUIノードなど）は除外。選ばれている理由や特徴が明記されている場合を強調。

#### 1. **Grok (xAIのマルチモーダルモデル)**
   - **>>862**: 「昨日の夜辺りにgrokのモデルがまた新しくなってwanにNSFW系LoRA使った時みたいに常に揺れてて高速動作するようになってしまった」
     - **特徴/理由**: 新モデル更新により、NSFW LoRA使用時のような「常に揺れて高速動作」する挙動に改善。高速化が魅力として言及。
   - **>>866**: grok久しぶりに使用、プロンプトなしで喋るようになり画像生成（チャッピー経由?）。
   - **>>893**: Grokでヒーローショー画像生成後、胸部強調指示で使用可能。
   - **全体文脈**: 画像生成の高速・動的挙動向上を評価。NSFWフィルタ弱化の願望も（>>892）。

#### 2. **HeartMuLa (音楽生成モデル、ComfyUI対応)**
   - **>>873**: 「HeartMuLaをsunoっぽいUIで扱う」 – UI実装話題。
   - **>>944**: 「この冬の寒さはグラボ暖房で乗り切るという決意を HeartMuraに歌にしてもらったで」 – 歌詞生成実例。
   - **>>952**: 「HeartMuLa_ComfyUIのサンプルGenerate Music.jsonがやっと動いた でも1時間半くらいかかった」 – 3060環境で動作確認、PV作成用途。**理由**: 軽量ワークフロー探し中、遊べるか疑問。
   - **>>959**: 「heartmulaは改良版モデルとcodec出てるで こっちダウンローするんやで」 – **改良版推奨理由**: 公式版より進歩、タグ効き向上（>>973で公式版のタグ効き悪さを指摘）。
   - **>>975**: 「軽く試した限りではHeartMuLa改良版は良くできてるで 進歩してる 7Bが待ち遠しいわ」 – **選定理由**: 改良版が高評価、タグ効き改善・進歩を実感。次世代7Bモデル期待。

#### 3. **Gemini (GoogleのLLM、マルチモーダル)**
   - **>>898**: 「ずっとCopilot使ってたけどGeminiに変えてみたが こういうプロンプトと書いてって指示してもバナナに丸投げして絵で返してくる」
     - **特徴**: プロンプト指示で画像生成に寄与するが、連携・出力形式に不満。
   - **>>927**: 「Geminiとか全く連携が出来てなくてイライラする」 – **理由（不満）**: 文章/画像生成の担当AI連携不足が短所。

#### 4. **Copilot (MicrosoftのLLM)**
   - **>>898**: 「ずっとCopilot使ってたけどGeminiに変えてみた」 – 従来使用モデルとして言及、Gemini移行の比較対象。

#### 5. **Sora2 (OpenAIの動画生成モデル?、割れアーカイブ言及)**
   - **>>967**: 「sora2とかで誰でもネタ動画作れるようになって」
   - **>>968**: 「Sora2なんか最近ニュースになった割れアーカイブ使ってなきゃ出せないクオリティ」
     - **特徴/理由**: 高クオリティ動画生成可能だが、公式以外（割れ）必須でアクセスしにくい。

### 抽出まとめ・傾向
- **総数**: 5モデル。主に画像/動画/音楽生成の文脈で、Grok/HeartMuLaが最も詳細に議論（速度向上・改良版の進歩が選好理由）。
- **除外確認**: Wan2.2/Qwen/banana(nano banana pro)/Dasiwanなど多数スキップ。bananaはPony/Noobai関連疑い濃厚で除外。
- **全体傾向**: ローカル環境（ComfyUI/グラボ）との親和性・速度/一貫性/改良版の進歩が評価軸。ストレージ/価格高騰の文脈でモデルサイズ大がネック（>>871など間接関連）。

不明点あれば追加抽出/確認します。