### 抽出された「ツール」に関する話題

ログから生成AI関連の「ツール」（ComfyUI/comfy, A1111, webUI, SUPIR, nano-bananaなど）に限定して抽出。モデル（NovelAI/NAI, Pony, illustrious/リアス/ill/IL, Noobai, FLUX/Wan, Qwenなど）に関する話題は除外。ツールが選ばれている理由（例: 速度、直感性、機能など）が明記されている場合のみ追記。

#### ComfyUI (comfy)
- **639**: comfyui0.11.1きたで  
  (新バージョン到着の話題)
- **668**: >>667 いつかforge neoみたいに対応してくれるやろ、多分 今焦って移る必要無いで  
  (Forge NEOのような対応を期待)
- **671**: webuiってAIでUI自作してcomyuiのフロント作れば解決する問題やからなあ 最低限上位モデルをある程度の回数叩ければ素人でも数時間あればwebUIより便利なの作れる時代や  
  (WebUIより便利なフロント自作可能)
- **672**: 直感的もなにもComfyUI環境を解説サイトのとおりに整えてテンプレ開いてモデルダウンロードして配置するだけで完了なのが今だぞ SD系統のタグプロンプト周りは拡張込みでWebUI系が優位だけど、Zimageには今のところそんなのないしComfyUIのテンプレワークフロー開いて解像度入力してポジティブとネガティブ入れるだけ  
  (テンプレワークフローで直感的・簡単、WebUI系よりタグプロンプトで劣るが解像度/プロンプト入力だけで完了)
- **732**: WebUI環境とエロOKでFTされたモデルが来るまでワイはリアスに籠るしか出来ない赤ちゃんや WANではしょうがなく触ってるけどどれだけ触ってもcomfyUIはなんか慣れん  
  (慣れにくい欠点指摘)
- **779**: forge neoの方ならComfy用のsafetensorを持ってきてLuminaモードで読み込めばWEBUIで一応生成できてるからComfy嫌い勢も試してみたらいいと思う  
  (Comfy用safetensor対応でForge NEO経由でWebUI利用可能)

#### WebUI / A1111 / WEBUI (Automatic1111系)
- **667**: z-imageに移る勇気がない…WEBUIが直観的でやりやすいんだよね…  
  (直感的でやりやすいため選好)
- **671**: webuiってAIでUI自作してcomyuiのフロント作れば解決する問題やからなあ 最低限上位モデルをある程度の回数叩ければ素人でも数時間あればwebUIより便利なの作れる時代や  
  (ComfyUIフロント自作で上回れるが、拡張込みでタグプロンプト優位)
- **672**: SD系統のタグプロンプト周りは拡張込みでWebUI系が優位  
  (タグプロンプト周りで優位)
- **732**: WebUI環境とエロOKでFTされたモデルが来るまでワイはリアスに籠るしか出来ない赤ちゃんや  
  (エロOK環境で使用継続)

#### AI-toolkit / AITOOLKIT
- **643**: AI-toolkitの使い始めでよくわからず取りあえず動かしてみたら、ステップ間のサンプル画像出力有効にしてて学習と関係ない処理でVRAMお漏らしして処理重くなりまくり……あると思います  
- **644**: >>643 まんま今のワイの状況なんやけどあれってOffにするべきやったんやろか  
- **646**: >>644 あったほうが途中経過見れて嬉しいけど、くっそ時間かかるからない方がいいっちゃいい CheckpointでSaveしてればAITOOLKITを完全停止したあとにそこから再開できるからチェックポイント到達したらいったん止めて生成環境立ち上げたほうが速い  
  (サンプル出力ONで時間/VRAM重くなるためOFF推奨、再開機能で速い)
- **648**: >>644 環境によるが、下手したら学習合計時間より合間の学習になんの影響もないサンプル出力に数倍時間掛かる恐れあるからな それなら学習終わってから各出力の完成度試した方がマシではある  
  (サンプル出力で時間数倍増のリスク)
- **664**: >>661 MusubiとAiToolkitってどっちがええんやろか  
- **685**: AitoolkitでZimageのLoraチャレンジ 設定はバッチ数を2にしたのとcache latnetをONにしただけ  
- **699**: >>685 AIToolkitのデフォルト設定だと「とりあえず手っ取り早くLoRAとして効果が出る」ような設定だから学習率が高い だから素材20枚でやると学習元に寄りすぎちゃって硬さが出る 学習率を半分や一桁下げて、その代わりに数倍のステップ数を回すだとかの沼への探索が始まる  
  (デフォルトで手っ取り早いが学習率高く硬さが出る)
- **777**: とりあえずai-toolkitのデフォ値からlr半分にしたら1000ステップくらいで発散するのは収まった ワイ感ではloraの出来もこっちの方が良さそう ai-toolkitで学習うまくいかない人は既定値より学習率下げてみるといいかもね  
  (デフォルト学習率下げで発散防ぎ、LoRA出来向上)
- **792**: ZimageをAIToolkitでNSFW学習させてみたんやけどTurboで学習した時は奇形だらけで微妙やったんやがZimageでの学習は割とええ感じやと思う 3060でオフロードは使ってTEを100%とトランスフォーマーを30%にして学習してキャプションはJoyCaptionAlpha使って学習解像度は512, 768, 1024で学習設定はデフォルトのままでlrも0.0001や  
  (デフォルト設定+lr0.0001でNSFW学習成功)
- **805**: musubi-tunerのほぼ公式設定でテスト　バッチ数は２ ステップは5000 AIToolkitデフォルトと比べて、出来はこっちのほうがいいかな　学習率は1e-4で同じなんだけど ただし時間は倍以上かかった　toolkit3.5時間　musubi8時間 Vram使用量もtoolkitは　20/32 musubi 28/32  
  (AIToolkitとMusubi比較で時間短くVRAM少なめ)

#### musubi-tuner / Musubi
- **636**: >>626 optimizerに自由度があるのはmusubi-tunerやね scheduleFree系使いたいとこれしか選択肢がない(それか自作するかしかない)  
  (optimizerの自由度高く、scheduleFree系を使いたい場合の唯一選択肢)
- **661**: musubi-tunerはZIでもxformersで地味に速くなるから入れ得やな  
  (xformers併用で地味に速くなるため入れ得)
- **664**: >>661 MusubiとAiToolkitってどっちがええんやろか  
- **805**: musubi-tunerのほぼ公式設定でテスト　バッチ数は２ ステップは5000 AIToolkitデフォルトと比べて、出来はこっちのほうがいいかな　学習率は1e-4で同じなんだけど ただし時間は倍以上かかった　toolkit3.5時間　musubi8時間 Vram使用量もtoolkitは　20/32 musubi 28/32  
  (AIToolkitより出来良いが時間/VRAM多め)

#### Forge NEO / NEO
- **668**: >>667 いつかforge neoみたいに対応してくれるやろ、多分  
- **679**: NEOを再起動したらcheckpoint: 996a67d3ffって出るようになったんやけど、どこ見たらこれがVersion 2.10って分かるん？  
- **779**: forge neoの方ならComfy用のsafetensorを持ってきてLuminaモードで読み込めばWEBUIで一応生成できてるからComfy嫌い勢も試してみたらいいと思う  
  (Comfy用safetensorをLuminaモードでWebUI生成可能)

#### xformers
- **661**: musubi-tunerはZIでもxformersで地味に速くなるから入れ得やな  
  (地味に速くなるためMusubi-tuner併用推奨)

#### その他（境界線上のツール言及）
- **733**: ワイはいまだにちょっとChroma2-Kaleidoscopeにほのかな期待をかけてる  
  (期待のツールとして言及、詳細なし)

これでログ内の全ツール関連話題を網羅。モデル名（Z-image, Wan, Qwen, リアスなど）が絡むレスでもツール部分のみ抽出。理由抽出は明示的な場合のみ。