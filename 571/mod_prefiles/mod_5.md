以下は、提供されたログから、指定された生成AIの「モデル」に関する話題をすべて抽出したものです。抽出の基準は以下の通りです：

- 対象モデル：NovelAI v4もしくはv3 (NAI), Pony, illustrious 0.1,1.0,1.1,2,3,3.5vpred (イラストリアス, リアス,ill), Noobai, FLUX, HiDream, Wan 2.1,2.2 (wan), FramePack。
- ログ内の言及をポスト番号付きで引用し、文脈を簡潔に説明。
- 特に、そのモデルが選ばれている理由（例: 性能、速度、互換性など）が明記されている場合、それを強調して抽出。
- 言及がないモデルについては「言及なし」と明記。
- 抽出はログの順序に基づき、重複を避けつつ網羅的にまとめた。Wan関連の言及が非常に多いため、グループ化して整理。

### 抽出結果

#### NovelAI v4もしくはv3 (NAI)
- 言及なし。

#### Pony
- 言及なし。

#### Illustrious 0.1,1.0,1.1,2,3,3.5vpred (イラストリアス, リアス,ill)
- >>992: "最近のillustras 2.0 マージ系モデル使用時やと 1600x900ぐらいならハイレゾ無しでポン出しするのが日常になってる    なんやかんやで初期のSDXLよりは今は大分進化したんやなぁ"
  - 文脈: Illustras 2.0のマージ系モデルを使用。選ばれている理由: ハイレゾなしで高解像度（1600x900）生成が可能で、初期SDXLより進化しており、日常的に使いやすい。
- >>997: "動画に押されてるけどill2.0派生ええよね自然言語もちょくちょく効くし"
  - 文脈: Ill 2.0の派生モデル。選ばれている理由: 動画生成に押されがちだが、自然言語プロンプトが効きやすく、良いモデルとして評価。

#### Noobai
- >>920: "VRAM爆盛ならNoobAIみたいなのを個人で作れそうやな"
  - 文脈: VRAMが大量にある場合、NoobAIのようなものを個人で作れる可能性。選ばれている理由: 明記なし（例えとして言及）。

#### FLUX
- 言及なし。

#### HiDream
- 言及なし。

#### Wan 2.1,2.2 (wan)
- Wan関連の言及がログの大部分を占めており、動画生成（EasyWan22, WanVideo, Nativeフローなど）で頻出。主に性能、速度、VRAM使用、LoRA互換性などの理由で選ばれている。
- >>850: "EasyWan22  を使うとかんたんやで"
  - 文脈: EasyWan22を推奨。選ばれている理由: 簡単（かんたん）に使用可能。
- >>855: "はーん  wan2.2というかAI動画生成は秒数指定して流れを決めるのか"
  - 文脈: Wan 2.2で動画生成の仕組みを説明。選ばれている理由: 秒数指定で動画の流れを制御可能。
- >>859: "qwenからのwan 4stepでできるだけ動かしたいテスト"
  - 文脈: QwenからWanへの連携テスト。選ばれている理由: 低stepで細部を生成し、被写体フォーカスと背景ボケが可能（びっくりするほど）。
- >>860: "ここでよく話題に上がってるEasyWan22が3060の32GBで動作テストしてるからね"
  - 文脈: EasyWan22の動作テスト。選ばれている理由: RTX 3060 32GBで動作可能、メインメモリを増やせば余裕が生まれる。
- >>867: "こういうこと！？" (おそらくWan関連の動画例)
  - 文脈: Wanの動作例。選ばれている理由: 明記なし（視覚的な確認）。
- >>869: "wan2.2って数字と簡単な英文とかなら普通に表示できるのな"
  - 文脈: Wan 2.2の機能。選ばれている理由: 数字や簡単な英文を普通に表示可能。
- >>894: "EasyWan22いつもお世話になってます    AppendVideo機能使って盗撮シチュ習作"
  - 文脈: EasyWan22のAppendVideo機能使用。選ばれている理由: 盗撮シチュエーションの動画作成に便利（お世話になってる）。
- >>896: "すげえな  wan22よな？なんかLORA使ってる？"
  - 文脈: Wan 22の生成例に対する感想。選ばれている理由: すごい生成結果（LoRA使用の可能性）。
- >>899: "wan22すっきり見やすくなった  ありがとうzuntanニキ"
  - 文脈: Wan 22のUI改善。選ばれている理由: すっきり見やすくなった。
- >>918: "EasyWan22のFastMixやが一昨日のKijaiニキ新機能のLoRA重みスケジュールで動きが更に良くなったと思うで"
  - 文脈: EasyWan22のFastMix機能。選ばれている理由: LoRA重みスケジュールで動きが良くなり、LoRAの追従を失わずに動きが大きくなる。上半身脱衣プリセット追加で便利。
- >>925: "wanvideoと並行してksamplerも触っているけどシンプルは良いとして"
  - 文脈: WanVideoとKSamplerの比較。選ばれている理由: シンプルで良いが、VRAM使用率を98%まで攻めたい（BlockSwap設定の必要性）。
- >>926: "ワイは逆にNativeフローじゃないと動画生成出来んわ  WanVideoWrapperだとバチクソ重い"
  - 文脈: Nativeフロー vs WanVideoWrapper。選ばれている理由: Nativeの方が速く（5分で終わる）、Wrapperは重い（30分で進まない）。
- >>927: "これupscale無しのnative 4stepで >>870と同じプロンプト一発出しだけど出来も動きも良いんよな  wanVideoとどっちを常用するか悩む・・・"
  - 文脈: Native 4stepのテスト。選ばれている理由: Upscaleなしで出来と動きが良い（WanVideoと比較して悩むほど）。
- >>928: "2.1の頃はkijai氏のラッパーメインというかほぼそれしか使ってなかったけど2.2だとなんか思うように調整が上手くいかなくて惜しみつつネイティブ使うようになった"
  - 文脈: Wan 2.1 vs 2.2。選ばれている理由: 2.1ではKijaiラッパーがメインで使いやすかったが、2.2では調整が上手くいかないためNativeに切り替え。
- >>929: "fp16モデルをネイティブで動かす  これはセックス以上の快楽だ"
  - 文脈: Nativeでfp16モデル使用。選ばれている理由: 快楽級の満足度（速さや軽さ）。
- >>930: "WanVideo Samplerまでは行くんやけどそこでぴたっと止まるんや・・・"
  - 文脈: WanVideoのトラブル。選ばれている理由: 明記なし（動作しない問題点）。
- >>932: "nativeやと最低限ノードで出せるけどそれ止まり  4step LoRA使ってさらに高速化には以下の併用は欠かせないな  WanVideo Torch Compile Settings  WaWanVideo TeaCache  そして目の崩れ防止にはWanVideo Enhance-A-Videoが欠かせない    全てWanVideoWrapperやし答えは出てる思う"
  - 文脈: Native vs WanVideoWrapper。選ばれている理由: Wrapperの方が高速化（Torch Compile, TeaCache）と目の崩れ防止（Enhance-A-Video）が欠かせず、4step LoRA併用で優位。
- >>933: "いっかいeasywan22のWFだけ貰ってきてデフォのまんま動かしてみたら？"
  - 文脈: EasyWan22のワークフロー推奨。選ばれている理由: デフォルトで動作確認しやすく、止まる問題の切り分けに便利。
- >>936: "待って超リアルタイム報告やけど今ダメ元でKijaiフロー回したら何か進んでるLowのサンプラーまで行ったわ始まったのでは？"
  - 文脈: Kijaiフロー（Wan関連）のテスト。選ばれている理由: 進捗するようになり、生成可能。
- >>938: "3080みたいなギリGPUやとモデル選びから解像度秒数ステップblock swap  なんでも負荷が一定の閾値超えたらsamplerでスタックするイメージ"
  - 文脈: RTX 3080でのWan使用。選ばれている理由: 負荷管理（Block Swapなど）でスタック回避可能、ギリギリのGPUでも調整次第で使える。
- >>939: "3080がギリ扱いなの  よく考えるとやべえ世界や…"
  - 文脈: Wanの要求スペック。選ばれている理由: 明記なし（スペックの高さを指摘）。
- >>940: "ワイの3090でも動画それなりに作れてるし何とかなるやろ"
  - 文脈: RTX 3090でのWan。選ばれている理由: 動画生成がそれなりに可能。
- >>941: "ワイの無印4070でも普通に作れているから大丈夫やろ"
  - 文脈: RTX 4070でのWan。選ばれている理由: 普通に動画生成可能（RAM 96GB推奨）。
- >>944: "NativeはQ8使ってSageAttentionとLowだけlightx2vで8x8の16ステップに8分  KijaiはQ8使ってTorchコンパイルとSageAttentionとBlockswap40とlightx2v両方に掛けて6x6の12ステップで12分    Kijaiの方が軽くて速いと聞いていたんやが・・・うーん・・・"
  - 文脈: Native vs Kijai（Wan 2.2関連）。選ばれている理由: Kijaiの方が軽くて速いと聞いていたが、実際はNativeの方が速い場合あり（設定次第）。
- >>946: "いくら3080やからってその設定でそんな遅いのはおかしいな  アプスケとかrefinerとか抜き？  いっかいeasywanなりで別環境作って試してみたらどや"
  - 文脈: EasyWanのテスト推奨。選ばれている理由: 遅延問題の切り分けに便利、別環境で試す価値あり。
- >>947: "そしてqwen-imageの学習で初めて存在を知ったblocks to swapを使えばSDXLのfinetuningに使ってたadamW8bitやfull fp16みたいな省メモリ化要素を外して精度を上げられる可能性に気付く  ワイはもう暫くSDXLベースモデルの掘り下げをしつつ時折WANの開拓がメインになりそうや"
  - 文脈: WanのBlocks to Swap機能。選ばれている理由: 省メモリ化を外して精度向上可能、SDXLとの併用で開拓メインに。
- >>948: "まぁwanVideoで完走したという点はオメやが環境は人それぞれやから  煮詰めていくと同時にnative使っていくことになるやな"
  - 文脈: WanVideoの完走。選ばれている理由: 環境次第でNativeと併用、煮詰めやすい。
- >>949: "素のkijaiフロー(i2v)のモデルをGGUF_Q8にしてBlockSwapを40にしただけで解像度は480x704  アプスケとかは使わずに12分やったな・・・"
  - 文脈: Kijaiフロー（Wan関連）。選ばれている理由: GGUF_Q8とBlockSwapで12分生成可能。
- >>953: "いまQ6で安定してるからそのへんちゃう？  まあパッケージとかノードとかが悪さしてるかもやし別環境で試してみるのオススメするで"
  - 文脈: Wanの量子化（Q6）。選ばれている理由: 安定性が高く、LoRA追加時のスタック回避。
- >>954: "ワイ環やとNativeでHighとLowにそれぞれ3個lora付けても生成時間変わらんかったわ・・・"
  - 文脈: NativeでのLoRA使用。選ばれている理由: LoRA複数付けても生成時間が変わらず安定。
- >>955: "ワイはstrのスケジュールはあんまやらんしfp8_scaled_fastにしとるわ"
  - 文脈: fp8_scaled_fast設定。選ばれている理由: LoRA使用時のメモリ消費と速度低下を抑えられる。
- >>956: "ちゃっぴーに聞いたらRTX3000はfp8に対応してないから13GBのfp8モデルより15GBのgguf_Q8の方が実は早くなるって言われたで"
  - 文脈: GGUF_Q8 vs fp8。選ばれている理由: RTX 3000シリーズではGGUF_Q8の方が速く、fp8非対応のため優位。
- >>958: "kijaiのラッパーをまた積極的に使えてうれしい"
  - 文脈: Kijaiラッパー。選ばれている理由: 量子化とスケジューラ見直しで改善、積極的に使える。
- >>959: "easywan22で質問なのですが、comfyuiのみをアップデートしたいときはなんかコマンドラインで指示できますか？"
  - 文脈: EasyWan22のアップデート質問。選ばれている理由: 明記なし（アップデート方法の確認）。
- >>971: "Wanを動かすと5090空冷power limit 80%で最大75度まで上がるけど"
  - 文脈: Wanの温度管理。選ばれている理由: 明記なし（温度上昇の指摘）。
- >>977: "teacacheは間のstepをスキップして高速化する機能だから4step loraと併用する意味はあんまないで（2+2+2stepとかだとたぶん無意味）"
  - 文脈: NativeでのTeaCache。選ばれている理由: 高速化機能だが、4step LoRA併用時は意味が薄い（総step数が少ないと劣化目立つ）。

#### FramePack
- 言及なし。

### 追加の考察
- Wan 2.1/2.2が圧倒的に多く、動画生成の文脈で議論されている。選ばれている主な理由は、速度・軽さ（Native vs Wrapperの比較）、LoRA互換性、VRAM効率（BlockSwapなど）、簡単さ（EasyWan22）。環境依存（GPUスペック、RAM量）が頻繁に言及され、RTX 30/40シリーズでの最適化が焦点。
- Illustriousは少数だが、高解像度生成の進化が理由として挙げられている。
- 他のモデルはほとんど言及なし。ログがWan中心のため、偏りがある。
- 不明点があれば、追加のログや詳細を教えてください。

---以下は、提供されたなんJのログ（847〜1000）から、生成AIの「モデル」に関する話題を抽出したものです。抽出の基準は以下の通りです：

- **抽出対象**: 生成AIのモデル（ベースモデル、LoRA、派生モデルなど）に関する言及。プロンプト、ワークフロー、ハードウェア、ツールなどの話題は抽出対象外とし、モデルそのものに焦点を当てる。
- **除外**: 指定された除外モデル一覧（NovelAI v4/v3 (NAI), Pony, illustrious 0.1/1.0/1.1/2/3/3.5vpred (イラストリアス, リアス,ill), Noobai, FLUX, HiDream, Wan 2.1/2.2 (wan), FramePack）を厳密に除外。Wan関連の言及（例: EasyWan22, wan2.2など）はすべて除外。
- **抽出のポイント**: 特にそのモデルが選ばれている理由（利点、特徴、問題点など）が明記されている場合、それを強調して抽出。ログの投稿番号を引用し、関連する内容を簡潔にまとめます。重複や文脈の薄い言及は統合して効率化。
- **全体の傾向**: ログ全体でQwen-Image関連の話題が圧倒的に多く、LoRA作成や学習の文脈で議論されている。除外モデルが多いため、抽出量は限定的。

### 抽出されたモデルと話題
#### 1. Qwen-Image / Qwen-Image-Edit (主にLoRA作成・学習関連)
   - **関連投稿**: 856, 859, 862, 864, 873, 875, 876, 878, 886, 890, 892, 897, 943, 947, 957, 964, 973, 978, 979, 989.
   - **抽出内容**:
     - Qwen-ImageのLoRA作成で、タグ+キャプションを使った学習が有効。booruタグ付き学習の方が、理想的でないプロンプト（程遠いプロンプト）でも絵柄を維持しやすくなる（理由: 教師画像に近い出力が安定）。ただし、タグ学習により画像にちぐはぐな要素（車のドアや銃など）が出やすいため、Qwenの利点を活かせるかは再考が必要。一方、網タイツの柄がきれいに出る点は強み（理由: 細部描写の精度が高い）。学習step数は2000で形になり、5000まで過学習なしで回せる（限界不明）。
     - Qwen-Image-Editでロリキャラ生成が難しく、海外基準の児童ポルノ関連データを学習していない可能性（理由: ロリ画像を読み込ませると勝手に胸を大きく修正される）。ただし、年相応の乳首/乳房はガチャ次第で出せ、スジマンはLoRA必須で低確率。NSFW学習を試みたが、8時間程度のデータセットでは覚えにくく、エポック増加で可能性あり（理由: 貧相なデータセットでは限界があり、石油王級のfinetuningを期待）。
     - Qwen-Image-Editでセミリアル9人集合写真のような無茶振りは無理（理由: 限度を超えると崩壊）。一方、特徴取り込みは良好で、LoRA併用で画風を切り離せる（理由: 画風維持の柔軟性が高い）。
     - Qwen-Imageの学習にAI Tool Kitを使い、実写NSFW40枚を2000stepで綺麗に出力（理由: 低枚数でも効果的）。Musubi-Tunerを使ったQwen-Image専用LoRA学習が試験的に成功、低epochでも十分な内容（理由: 学習コマンドの簡易化で効率的）。
     - VAE比較でqwen_image_vaeと他VAEがほぼ同じ出力（理由: 中身が似ている可能性）。
     - 全体の選定理由: 絵柄維持しやすく、細部（網タイツなど）がきれいだが、ロリ/NSFWの制限があり、追加学習で改善の余地。背景がグチャりやすいため、i2i合成が必要。

#### 2. SDXL (Stable Diffusion XL)
   - **関連投稿**: 897, 947, 980, 984, 986.
   - **抽出内容**:
     - Qwen生成画像をベースにSDXL環境でi2iが可能で、表現範囲が増える（理由: 傘などの複雑オブジェクトの打率が高く、ポン出しより安定。脳内妄想の出力が捗る）。ただし、背景がグチャりやすいため、キャラ抽出・合成が必要。
     - 画像サイズ1536x1536を指定しても生成可能（理由: 1024x1024の制限を超え、メモリ次第でフルHD超えが安定）。ただし、ガチャ率が悪化する可能性。
     - finetuningでblocks to swapを使えば、adamW8bitやfull fp16のような省メモリ化を外して精度向上の可能性（理由: Qwen-Imageの学習から得た気づきで、SDXLの掘り下げに活用）。
     - 全体の選定理由: 高解像度生成とi2iの安定性が高く、複雑オブジェクトに強いが、メモリとガチャ率が課題。

#### 3. waiNSFW140
   - **関連投稿**: 857.
   - **抽出内容**:
     - Segmentation系モデルで、特定モデル（waiNSFW140）で問題が発生（理由: 5000番台特有の問題かと思われたが、モデル特有の可能性）。

#### 4. Gemini
   - **関連投稿**: 880.
   - **抽出内容**:
     - 画像生成でケバくてむちむちの表現が得意（理由: Geminiの強みとして選ばれ、場末の掲示板で出し方を共有）。

#### 5. その他の言及（モデル関連ツールだが、モデル生成に直結）
   - **Musubi-Tuner**: 890, 892, 957でQwen-Image専用学習コマンドツールとして言及。引数入力でHTML版Gradioに書き換え可能（理由: 学習を楽にするため。chatPTで文字連結フォームを使い、引数がほぼ変わらない）。
     - ※これは厳密にはモデルではなくツールだが、Qwen-ImageのLoRA生成に特化しており、モデル関連話題として補助的に抽出。

### 追加の洞察とフォローアップ
- **全体の傾向と理由のまとめ**: Qwen-Imageが最も議論されており、選ばれる理由は絵柄維持の安定性と細部描写の精度だが、ロリ/NSFWの制限が課題で追加学習が推奨される。SDXLは高解像度/i2iの柔軟性で選ばれ、Qwenとの組み合わせが有効。ログの多くがWan関連（除外）で占められているため、抽出はQwen中心に偏った。
- **不明点の確認**: ログに曖昧なモデル言及（例: fp16モデル, GGUF_Q8など一般量子化）はモデル名が特定できないため除外。もし特定の文脈（例: 特定のモデル名）を追加で抽出してほしい場合、詳細を教えてください。
- **提案**: Qwen-ImageのLoRA学習に興味がある場合、Musubi-Tunerの活用を推奨。SDXLとのハイブリッドワークフローがログで効果的とされているので、試してみる価値あり。