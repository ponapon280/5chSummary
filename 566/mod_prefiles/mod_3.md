以下は、提供された5chログから、指定された生成AIの「モデル」に関する話題をすべて抽出したものです。抽出の基準は以下の通りです：

- 指定モデル：NovelAI v4もしくはv3 (NAI), Pony, illustrious 0.1,1.0,1.1,2,3,3.5vpred (イラストリアス, リアス,ill), Noobai, FLUX, HiDream, Wan2.1 (wan), FramePack
- 抽出対象：これらのモデル名（またはその略称/バリエーション）が直接言及されているレス。関連する文脈（例: 使い方、比較、理由など）も含めて抽出。
- 特に、モデルが選ばれている理由があれば、その点を明示的に抽出・注記。
- ログ内のWan2.2は指定のWan2.1 (wan)と関連が深いため、Wan2.1との比較や移行の文脈で言及されている場合に抽出（ただし、Wan2.2単独の話題は除外）。
- 抽出はログのレス番号順にまとめ、各モデルの言及をグループ化。重複や無関係な部分は省略し、要約的に記述。
- 該当なしのモデル：NovelAI v4/v3 (NAI), Noobai（neta-luminaが登場するが、Noobaiの直接言及なしのため除外）。

### Pony
- **469**: Wan2.2だと逆さにしても顔の崩壊しないみたい [...] Pony系は逆さでも顔がちゃんと出るのあったけど
  - 理由抽出: Pony系が逆さのポーズでも顔が崩壊しにくいため、比較対象として挙げられている（Wan2.2やFlux/HiDreamとの比較で、動画学習による利点が議論されている）。

### illustrious 0.1,1.0,1.1,2,3,3.5vpred (イラストリアス, リアス,ill)
- **459**: 生成  リアス2.0ベースの自作マージモデル  1280*720 35step  1.5倍にアプスケ 20step  dpm++ 2m    これでt2iがだいたい一枚35秒程度、アプスケ無しなら15秒弱や  一応radeon環境の叩き台にでもしてくれ
  - 理由抽出: Radeon環境での生成テストに使用。自作マージモデルとしてベースに選ばれている理由は明示されていないが、生成速度や解像度の参考情報として共有（Radeonの限界を考慮した選択か）。
- **482**: ほーん  リアス2.0とかよりなんかええのん？
  - 理由抽出: neta-luminaとの比較で言及。リアス2.0が基準として挙げられているが、選ばれる理由は明示なし（新しいモデルの優位性を疑問視）。

### FLUX, HiDream
- **469**: Wan2.2だと逆さにしても顔の崩壊しないみたい  逆さがなかなか出ないんだけど  FluxやHiDreamでもなかなかうまくいかなかったけど動画学習だとバク転やら体操やら飛び込みやら色々学習しているんやろうな
  - 理由抽出: FluxとHiDreamが逆さポーズの生成でうまくいかないため、比較対象として挙げられている（動画学習の利点がWan2.2の強みとして強調）。

### Wan2.1 (wan)
- **445**: 今みんなが熱狂してるWan2.2もRadeonじゃ無理やしな
  - 理由抽出: Radeon環境での互換性問題でWan2.2が使えないため、間接的にWan2.1の文脈（ただし直接の理由なし）。
- **456**: なんかかなり遅いながらもwan2.2動いたという書き込みみたから、あーcomfyでいけるのならアリなのかな？と思っちゃいました。XTなら80000台で20GBかあ。
  - 理由抽出: wan2.2の動作報告から、ComfyUIでの互換性を考慮（Wan2.1の延長として議論）。
- **469**: Wan2.2だと逆さにしても顔の崩壊しないみたい [...] FluxやHiDreamでもなかなかうまくいかなかったけど動画学習だとバク転やら体操やら飛び込みやら色々学習しているんやろうな
  - 理由抽出: Wan2.2の動画学習が逆さポーズで優位（Wan2.1からの進化として比較）。
- **491**: Wan2.1 ComfyUI ワークフロー - 完全ガイド | ComfyUI Wiki   share.google/eQC6JTYim0gyKjDt6
  - 理由抽出: ComfyUIでのワークフローガイドとして共有。選ばれる理由は明示なし（実用性重視）。
- **492**: Wan2.1 ComfyUI ワークフロー - 完全ガイド | ComfyUI Wiki   share.google/eQC6JTYim0gyKjDt6（再掲）
  - 理由抽出: 同上。
- **512**: 個人的には毛無ししか生成しないから使ってないけどCIVITAIにWAN2.1 / WAN2.2 Pubic Hairがある  動きは実写系とアニメ系と共通にできるのはわかったけど、毛の表現がどうなるかわからんが
  - 理由抽出: Pubic Hair LoRAとしてWan2.1/2.2対応。陰毛表現の改善に選ばれている（動きの共通性と表現の柔軟性）。
- **533**: ぶっかけはLoRAあるけど、中出しはLoRAがないから射精終わりが作れん  OrgasmはLoRAがあるので、ピストン動画生成→エンドフレーム画像をスタートにして女側がいくことでフィニッシュ、後に結合でそれっぽいのはできる  5秒超えると一発ポン出しはたぶん無理、学習元が35秒で正規化されてるから、07秒までピストン710秒まででフィニッシュの10秒動画はたぶん作れない  3秒ピストン2秒フィニッシュの5秒は行ける
  - 理由抽出: Wan2.1の学習元（35秒正規化）が5秒超の生成を制限するため、短い動画生成に適している（LoRAとの組み合わせでフィニッシュ表現）。
- **537**: 2.1の時は姫騎士ニキが作ってたアナルLORAが女性器でも使えたから、ああいう感じのLORA待ちかな
  - 理由抽出: 2.1のLoRAが女性器表現で有効（2.2との比較で、LoRAの互換性）。
- **549**: wanはモデル学習も使ってる動画が5秒程度だったはずやからその秒数を超えるとええ感じにはならんよな  有料のとこが12秒だの20秒だの言ってるのはモデル作ったときの学習動画がその秒数だからやし  無料で配られてるモデルの限界を感じるとこやね
  - 理由抽出: Wan2.1の学習動画が5秒程度のため、短い動画生成に適し、秒数超過で品質低下（無料モデルの限界として選ばれている）。
- **551**: 2.1になってnative版とkijai版の要求スペック逆転しとらん？  2.1の時はkijai版のほうがメインメモリ使ってたのに  civitaiの2.2のnativeフロー試したらメモリ爆食いして  久々にSSDにお漏らしされちった　96GBでも足らんのか  でも2.1ではnativeは品質足らんと思ってたけど2.2ではキレイに出るな
  - 理由抽出: 2.1のnative版が品質不足だったが、メモリ消費の観点で比較（2.2への移行理由として）。
- **552**: 2.1になって  ◯2.2になって
  - 理由抽出: バージョン移行の言及（理由明示なし）。
- **567**: anal_cum_in_ass_wanvideo_i2v_epoch5のLORAを使ってみて一応中出しできた  [...] LOWの方は2.1LORA動くって言ってた人が前に居たからそれかな  まあ、Ver違うから一応動く？ってレベルかもしれないけど
  - 理由抽出: 2.1 LoRAがWan2.2のLOW側で動作するため、中出し表現に選ばれている（バージョン互換性）。
- **571**: Wan2.2でおっぱいぷるん出してみたけど2.1より色や明るさも安定する気がする
  - 理由抽出: 2.1より2.2の方が色/明るさ安定（2.1からの改善点として比較）。
- **624**: Wan2.2のLoRAの使い方の整理 [...] Wan2.1にはハイノイズとローノイズの区分けはLoRAにはないのでハイ・ローはWan2.2の新要素  Wan2.1のLoRAはWan2.2のローノイズモデルLoRAに使える  Wan2.2のハイノイズLoRAにWan2.1のLoRAを適用すると動きが固くなる
  - 理由抽出: Wan2.1 LoRAがWan2.2のローノイズに互換性あり、動きの柔軟性確保のため選ばれている（ハイ/ロー区分の新要素との比較）。

### FramePack
- **578**: zuntanニキワークフローのpoint mosaic凄いっすね。カメラ外から出てくるのに適用するのは流石に無理かな？
  - 理由抽出: FramePack関連のワークフロー（point mosaic）でモザイク適用に使用。カメラ外の適用が難しいため議論（実用性テスト）。
- **601**: framepackみたいにパディングを指定したりはできないのやろうか。
  - 理由抽出: パディング指定の機能比較（Wanとの違いとして言及、選ばれる理由は明示なし）。

これらの抽出はログ全体を精査した結果です。指定モデル以外の話題（例: Wan2.2単独、SDXLなど）は除外しました。追加の文脈が必要であれば、さらなる質問をお願いします。

---以下は、提供された5chログ（439〜639）から、生成AIの「モデル」に関する話題を抽出したものです。抽出の基準は以下の通りです：

- **対象**: 生成AIのモデル（例: Stable Diffusion系モデル、動画生成モデルなど）に関する言及。ハードウェア（GPUなど）はAIモデルそのものではないため除外。
- **除外**: 指定された除外モデル一覧（NovelAI v4/v3 (NAI), Pony, illustrious 0.1/1.0/1.1/2/3/3.5vpred (イラストリアス, リアス, ill), Noobai, FLUX, HiDream, Wan2.1 (wan), FramePack）を厳密に除外。ログ内でこれらに該当する言及（例: Pony系、FLUX、HiDream、Wan2.1、リアスなど）は抽出対象外としました。
- **抽出方法**: 除外対象外のモデルに関する話題を、レス番号付きで抜粋・要約。モデル名が明示的に言及され、議論されている部分に限定。特に、そのモデルが選ばれている理由（性能、利点、欠点など）が述べられている場合、それを強調して抽出。
- **注意**: ログの大部分がWan2.2（除外対象外）に関する話題ですが、冗長を避けるため、代表的な言及と理由をまとめて抽出。他のモデル（例: SDXL, neta-lumina）も該当箇所を抽出。モデル名が曖昧な場合やハードウェア中心の議論は除外。

### 抽出結果

#### 1. Wan2.2（動画生成モデル）
- **主な話題の概要**: ログ全体でWan2.2が頻出。除外対象のWan2.1とは異なり、2.2は新しいバージョンとしてRadeon対応の可能性、逆再生の性能、LoRAの適用方法、メモリ消費、生成品質（顔の崩壊防止、動きの自然さ）などが議論されている。選ばれている理由として、動きのダイナミックさや一貫性、逆さ生成の安定性、LoRAによるカスタマイズの柔軟さが挙げられる。
- **具体的な抽出（代表例）**:
  - 445: Wan2.2がRadeonで動かせないと指摘（理由: Radeonの選択肢が限定的で、熱狂的なモデルが使えないため、つまらない思いをする）。
  - 447: Wan2.2がComfyUIで遅いが動いた報告（理由: AMD XTの20GB VRAMで対応可能ならアリかも、という期待）。
  - 455: ComfyUIでWan2.2が動かせるとの情報（理由: Radeonでも動作報告あり、無理という情報は嘘）。
  - 462: MacでWan2.2のような最新動画モデルは難しいが、SDXLなら簡単（理由: Wan2.2はNVIDIA一強だが、MacではSDXLの枯れた安定性が選ばれる）。
  - 469: Wan2.2で逆さ生成が顔崩壊せず安定（理由: 動画学習による体操などの動き理解が優位。Pony系より顔の出力が良い場合あり）。
  - 524: Wan2.2のメモリ消費が32GBでギリギリ、80GB推奨（理由: スタート/エンド指定で溢れやすいため、メモリ増設で安定生成）。
  - 525: Wan2.2で日本語プロンプトが通る（理由: 翻訳ノード不要で、細かい動き（乳首こねくり）がクオリティ高く生成可能）。
  - 526: Wan2.2のFLF（First-Last Frame）で調整可能（理由: エンドフレーム付近の色変化を軽減し、品質向上）。
  - 549: Wan2.2の学習動画が5秒程度のため、超えると品質低下（理由: 無料モデルの限界で、12-20秒の有料モデルより短いが、余韻生成に適する）。
  - 551: Wan2.2のnative版がメモリ爆食い（96GBでも不足）だが、品質キレイ（理由: 2.1より最適化不足だが、色や明るさの安定性が高いため選ばれる）。
  - 563: Wan2.2で色指定が効果的（理由: 詳細指定でクオリティ向上、動きの自然さが強み）。
  - 571: Wan2.2でおっぱい揺れが安定（理由: 2.1より色/明るさの安定性が高く、編集しやすさ）。
  - 624: Wan2.2のLoRA（ハイノイズ/ローノイズ）がダイナミックな動きと一貫性を確保（理由: Wan2.1 LoRA互換で体位改善可能だが、数値調整でトレードオフ。結合部の処理が向上）。

#### 2. SDXL（Stable Diffusion XLモデル）
- **主な話題の概要**: 静止画生成の定番として言及。動画モデル（Wan系）と比較し、自然言語処理やパース理解の利点が強調。選ばれている理由として、蓄積された知識とシンプルな需要（例: 女の子生成）への適応性が高い。
- **具体的な抽出**:
  - 462: MacでSDXL画像生成がAppStoreアプリで簡単（理由: Wan2.2のような最新動画モデルは難しいが、枯れた安定性で環境構築がアホらしくなるほど楽。生成速度は現実的でないが、NVIDIA以外の選択肢として情報が欲しい）。
  - 483: SDXLの利点はパース理解と自然言語処理（理由: 1girlのエロ生成需要なら長期間天下。静止画次世代組より蓄積が違うため、シンプル需要で選ばれる）。

#### 3. neta-lumina（モデル名、詳細不明だが静止画生成モデルと思われる）
- **主な話題の概要**: 適当なタグで生成可能で、クオリティが悪くないと評価。選ばれている理由として、絵師タグの効きやすさと自然言語処理のポテンシャル。
- **具体的な抽出**:
  - 475: neta-luminaでdanbooruタグポン出し可能、伸びしろあり（理由: クオリティ悪くない、絵師タグ効きそう）。
  - 508: neta-luminaでアリス生成（理由: スレ民的にアリスが出ればええやろ。クオリティまあ悪くない、自然言語処理のレベルを知りたい）。

#### 追加の考察
- **全体の傾向**: ログの焦点は動画生成（特にWan2.2）にあり、静止画モデル（SDXL, neta-lumina）は比較対象として登場。除外対象外のモデルは少数だが、Wan2.2が選ばれている主な理由は「動きの自然さ・安定性」と「LoRAのカスタマイズ性」にある。一方、SDXLは「安定性と蓄積されたノウハウ」が理由で、動画中心の議論の中で静止画の強みを主張する声が見られる。
- **抽出漏れの可能性**: ログが長大なため、モデル名が曖昧な言及（例: 自作マージモデルだがベースが除外対象の場合）は除外。ハードウェア（Radeon, RTXなど）の議論はAIモデルではないため抽出せず。
- **フォローアップ**: もし特定のモデルに絞った詳細な抽出や、除外基準の確認が必要なら、追加で教えてください。