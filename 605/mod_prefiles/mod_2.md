### 抽出結果: 指定モデルに関する話題

ログ全体をスキャンし、指定されたモデル（NovelAI (NAI), Pony, illustrious(イラストリアス, リアス,ill,IL), Noobai, FLUX, Wan, Qwen）に関する言及をすべて抽出。PonyとQwenは一切言及なし。以下にモデルごとにまとめ、各言及の文脈と引用を記載。特に「選ばれている理由」や評価・使用理由が明示的なものは**太字**で強調。

#### NovelAI (NAI)
- **291**: 「当時NAIあたりからスレに入り浸っていたワイも初めて知ったんや…」  
  → NAIを過去の使用経験として言及（スレ参加の文脈）。選定理由なし。

#### illustrious (イラストリアス, リアス, ill, IL)
- **339**: 「ようやくAnyIllustrious-XL使ってみて学習元の画風乗らんのが凄いんやけど 元の画風が欲しい場合もあるンゴね」  
  → AnyIllustrious-XLを使用した感想。**学習元の画風が乗らない（良い意味で汎用的？）点を評価しつつ、元の画風を再現したい場合の課題を指摘**。
- **367**: 「解剖学に厳密なリアス系モデルは欲しい」  
  → リアス系モデルを**解剖学の厳密さで欲している**（希望・選好理由明示）。

#### Noobai (Noob, ChenkinNoobなど関連)
- **373**: 「ChenkinNoob V0.2がそろそろ出そう（現在承認制）」  
  → ChenkinNoob V0.2のリリース期待を言及。選定理由なし。
- **419**: 「そもそもZITってnoobのデータ求めとるぐらいやからdanbooru使った学習自体ほとんどされてないんちゃうの booruタグ効くんならキャラだのエロだのもデフォで出せるやろうし」  
  → NoobのデータをZITが求めている文脈で、Danbooruタグ学習の少なさを指摘（モデル特性の分析）。

#### FLUX
- **296**: 「あと4090から5090だとSDXLの体感速度は変わらん気がする 赤ちゃん設定のせいかもしれんが **FLUX.2で高解像度出すのにVRAMとメモリ底上げしないとついていけんから変えたけど**」  
  → FLUX.2を**高解像度生成時のVRAM/メモリ要件の高さから、GPU/メモリ強化の理由として選んだ**（明確な選定理由）。

#### Wan (WAN, Wan2.2, wai, Smoothmix, DaSiWaなど派生含む)
- **273**: 「5090使用でPyTorch2.7.12.9.0までのバージョン全部にXformers入れて確認したことあるけど、Xformersの有無で全く生成速度変わらんかったわ、**SDXLとWANしか見てないけどね** それはそうとPyTorch2.11.0が出てたから試したけど、生成そのものは僅かに早くなった代わりに**WANのVAE処理時にVRAMを倍以上食うようになって溢れてアカンかったわ**」  
  → WANをテスト対象として使用。**VAE処理時のVRAM消費が大きい欠点**を指摘。
- **324**: 「comfy公式**wan2.2ワークフローをQ8ggufにしただけの初動画漏れ漏れ？で遅すぎて草** loaded partially 5234.84 MB usable, 5012.94 MB loaded, 9812.53 MB offloaded 70s/itとかシナシナになっちゃうよ」  
  → Wan2.2のワークフローをQ8 GGUFでテスト。**速度が遅く漏れやすい欠点**。
- **371**: 「wai v16は良い意味で変わってないな 基本は変化なくて、人体構造や手指の破綻は減った感じ まだまだnが少ないから何とも言えないが今のところ好印象」  
  → Wai V16を**人体構造/手指の破綻減少で好印象**（ポジティブ評価）。
- **374**: 「waiは9が好き過ぎて先に進めない」  
  → Waiの「9」（おそらく特定のバージョンや要素）を好みすぎて進まない。
- **429**: 「**素のWan2.2→高速化LoRAは実質必須、おっぱいカチカチなのでエロLoRAも必須、プロンプトよりもLoRA強度で動きが決まる**  **Smoothmix→高速化LoRAは組み込み済みなので不要、エロLoRAも組み込み済みなので基本不要、プロンプトで素直に動くが理解させるような表現探すのが大変、エロLoRAを追加可能だが暴走しがち**  **DaSiWa→高速化LoRAは組み込み済みなので不要、エロLoRAも組み込み済みだがSoomthmixに比べるとエロ動きが弱い、エロLoRAを追加するといい感じになる** プロンプトだけでかなりいけるSmoothmixが便利だけどすぐに腰振るし、隙あらば画面外からチンコ挿入しようとしてくる あんまり触れてないけど、Smoothmixがメインで、LoRAの動きにこだわるならDaSiWa+エロLoRA強度調整かなという印象」  
  → Wan2.2 / Smoothmix / DaSiWaの詳細比較。**Smoothmixをプロンプト対応の便利さでメイン推奨、LoRA依存度やエロ表現の特性を理由に使い分け**（選定理由詳細）。

### まとめ
- **総言及数**: NAI(1), Illustrious系(2), Noobai系(2), FLUX(1), Wan系(7)。
- **選定理由の傾向**: FLUXは高解像度対応、Illustriousは画風汎用性/解剖学厳密さ、Wan系はLoRA統合/プロンプト対応/速度/エロ表現のバランスで積極的に議論。欠点（VRAM消費、速度遅延）も併記。
- 他のモデル（Pony, Qwen）はゼロ。ログはGPU/ツール中心でモデル話題は散発的。

---

### 抽出された生成AIモデル関連話題（除外モデルを除く）

ログ全体から、生成AIの「モデル」名（主にStable Diffusion系や派生モデル）を特定し、除外リスト（NovelAI/NAI, Pony, illustrious/イラストリアス/リアス/ill/IL, Noobai, FLUX, Wan, Qwen）に該当しないものを抽出。ツール（ComfyUI, A1111/Forge/Reforgeなど）やLoRA/VAE/ノードなどの周辺要素は除外。モデル名が明確で話題になっている箇所のみ対象とし、選ばれている理由や文脈を簡潔に記述。

#### SD1.5
- **234**: SD1.5 1280x640 40 step, hires x1.5 20 stepの生成速度比較（5090/3060 GPU）。5090で高速（8sec/13GB VRAM）な点が強調。**理由**: 高速生成とメモリ効率のベンチマークで言及。

#### SDXL
- **273**: 5090でPyTorch各種バージョン+SDXLテスト。Xformers無効でも速度変わらず、PyTorch2.11.0で生成速いがVAE処理でVRAM倍増・溢れ。**理由**: 5090の高解像度生成テストで使用、WANと併用比較。
- **296**: 4090→5090換装でSDXL体感速度変わらず。FLUX.2の高解像度でVRAM/メモリ底上げ必要。**理由**: 高解像度生成の安定性で選好、FLUX.2のVRAM不足解消目的で5090換装。

#### wai (v16含む)
- **371**: wai v16は人体構造/手指破綻減、好印象。**理由**: 安定性向上（変化少なく破綻減）が好評。
- **374**: waiは9が好き過ぎて先に進めない（おそらくv9固定？）。**理由**: 特定のバージョン（9?）の出力特性が気に入り継続使用。

#### Smoothmix
- **425**: 赤ちゃん設定のSmoothmixでNSFW（下半身寒い）。LoRA不要か調整か質問。
- **429**: Smoothmixは高速化/エロLoRA組み込み済み、プロンプト素直に応じるが理解表現探し大変・暴走しがち。**理由**: LoRA不要でプロンプト中心の便利さ（腰振り/チンコ挿入傾向あるがメイン推奨）。

#### DaSiWa
- **429**: DaSiWaは高速化/エロLoRA組み込みだがSmoothmixよりエロ動き弱く、エロLoRA追加で良化。**理由**: LoRA強度調整でエロ表現強化可能、Smoothmixの補完として。

#### Z-Image (Turbo/ZIT/Zbase/ZimageBase含む)
- **361**: ZimageBase来ないのが悪い。
- **366**: Zbase来ず。
- **416**: グリッドWFでZITの髪型テスト、Danbooruタグ影響微妙。
- **417**: Z-Imageみたいに自然言語対応モデル増える？英文必要か。
- **419**: ZITはnoobデータ求めでDanbooru学習少なめか。
- **430**: Z-Image Turboは日本語自然文通る、陥没乳首出ず（ちんちん残念）。**理由**: 自然言語対応の高理解度（日本語直入力可能）が魅力。

#### その他（文脈的にモデル名と推定）
- **339**: AnyIllustrious-XL（除外のためスキップ）だが、学習元画風乗らない点を言及し「元の画風欲しい場合もある」と一般論。
- **403**: Asuma（ちびたい配布モデル？ 前配布と別か確認）。文脈不明だがモデル関連。
- **373**: ChenkinNoob V0.2（Noobai関連で除外）。

**全体傾向**: ハードウェア（5090 GPU/メモリ増強）との相性でSD1.5/SDXLが速度/高解像度テストに多用。Smoothmix/DaSiWaは動画/エロ特化の利便性（LoRA内蔵）。Z-Image系は自然言語対応の将来性期待。理由は主に「速度/安定/エロ表現/自然言語理解」の実用性。